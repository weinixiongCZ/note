#CS

# 参考书籍
- [[计算机组成与设计 硬件软件接口.pdf]]
- [[计算机组成与设计 硬件软件接口-答案.pdf]]

# 第1章 计算机概要与技术

## 1.1 引言

### 1.1.1 计算机分类及其特性

- 个人计算机：用于个人使用的计算机，通常包含图形显示器、键盘和鼠标等
- 服务器：用于为多用户运行大型程序的计算机，通常多个用户并行使用，并且一般通过网络访问 ^6ec83f
- 超级计算机：具有最高性能和最高成本的一类计算机，一般配置为服务器，需要花费数千万甚至数亿美元
- 嵌入式计算机：嵌入到其他设备中的计算机，一般运行预定义的一个或一组程序

### 1.1.2 后PC时代

- 个人移动设备：连接到网络上的小型无线设备。PMD由电池供电，通过下载 App 的方式安装软件。
- 云计算：在网络上提供服务的大型[[计算机组成与设计#^6ec83f|服务器]]集群，一些运营商根据应用需求出租不同数量的服务器。

| 软件或硬件 | 该元素如何影响性能 | 该论题出现的位置 |
| ------------| --------- | ---------------- |
| [[算法]]| 了源码语句和I/O操作的数量 | [[算法导论.pdf]]|
| [[编程语言]]、编译器和[[体系结构]]| 决定了每条源码级语句对应的计算机指令数量|第[[计算机组成与设计#第2章 指令：计算机的语言\|2]]、[[计算机组成与设计#第3章 计算机的算术运算\|3]]章|
| 处理器和存储系统 | 决定了指令的执行速度|第[[计算机组成与设计#第4章 处理器\|4]]、[[计算机组成与设计#第5章 大容量和高速度：开发存储器层次结构\|5]]、[[计算机组成与设计#第6章 从客户端到云的并行处理器\|6]]章 |
| [[IO]]系统|决定了I/O操作可能的执行速度| 第[[计算机组成与设计#第4章 处理器\|4]]、[[计算机组成与设计#第5章 大容量和高速度：开发存储器层次结构\|5]]、[[计算机组成与设计#第6章 从客户端到云的并行处理器\|6]]章 |

## 1.2 计算机系统结构中的8个伟大思想

1.  面向摩尔定律的设计：摩尔预测单[[计算机组成与设计#^dcfcd2|芯片]]的集成度每18~24个月翻一番，由于计算机设计需要几年时间、所以计算机设计者要预测设计完成时的工艺水平，而不是开始的，否则完成设计就落伍了
2.  使用抽象简化设计：在高层次设计中看不到低层次设计的细节，只能看到一个简化的模型
3.  加速大概率事件比优化小概率事件更能提高性能
4.  通过[[计算机组成与设计#^5acef3|并行]]提高性能
5.  通过[[计算机组成与设计#^9ceefe|流水线]]提高性能
6.  通过预测提高性能：在某些情况下，如果假定从误预测恢复执行代价不高并且预测的准确率相对较高，则通过猜测的方式提前开始某些操作，要比等到确切知道这些操作应该启动时才开始要快一些。
7.  [[计算机组成与设计#5.8 存储器层次结构的一般框架|存储器层次]]：在存储器层次中，速度最快、容量最小并且每位价格最昂贵的存储器处于顶层，而速度最慢、容量最大且每位价格最便宜的存储器处于最底层。
8.  通过使用冗余部件的方式提高系统的可靠性

## 1.3 程序概念入门

软件硬件层次：中心是硬件、外层是应用软件、系统软件位于两者之间

- 系统软件：提供常用服务的软件，包括[[操作系统]]、编译程序、加载程序和汇编程序等。
    - 操作系统：为了使程序更好地在计算机上运行而管理计算机资源的监控程序。
        - 处理基本的输入和输出操作。
        - 分配外存和[[计算机组成与设计#^21ca0e|内存]]。
        - 为多个应用程序提供共享计算机资源的服务。
    - 编译程序：将高级语言翻译为计算机所能识别的机器语言的程序。
        - 二进制位：也称为位。基数为2的数字中的0或1，它是信息的基本组成元素。
        - 指令：计算机硬件所能理解并服从的命令。 ^785021
        - 高级编程语言：如C、C+ +、[[Java|Java]]、Visual Basic 等可移植的语言，由一些单词和代数符号组成，可以由编译器转换为[[汇编语言]]。使用高级编程语言的好处如下：
            1.  程序员可以用更自然的语言思考
            2.  提高了程序员生产率，使用较少的行数即可设计程序
            3.  提高了程序相对于计算机的独立性

## 1.4 硬件概念入门

- 输入设备：为计算机提供信息的装置，如键盘。
- 输出设备：将计算结果输出给用户（如显示器）或其他计算机装置。

### 1.4.1显示器

- 液晶显示：这是一种显示技术，用液体聚合物游层的带电或者不带电来传输或者阻止光线的传输。
- 动态矩阵显示：一种液晶显示技术，使用晶体管控制单个像素上光线的传输。
- 像素：图像元素的最小单元。屏幕由成千上万的像素组成的矩阵而形成

### 1.4.3 打开机箱

- 集成电路：也叫芯片，一种将几十到上百万个晶体管连接起来的设备
  
- 中央处理单元（CPU）：也叫处理器，包括数据通路和控制器。
  
    - 数据通路：执行算数运算
    - 控制器：根据程序指令指挥数据通路、存储器、I/O设备工作

- 内存：程序运行时的存储空间，同时存储程序运行时所需的数据，由许多DARM组成
   ^21ca0e
- DARM：动态随机访问存储器，集成电路形式的存储器，可随机访问任何地址的内存
   ^07ddc2
- 缓存：缓存是一种小而快的存储器，一般作为大而慢的存储器的缓冲。
  
- SRAM：静态随机访问存储器，一种集成电路形式的存储器，但是比DRAM更快，集成度更低。
  
- 指令集体系结构：也叫[[体系结构]]，是低层次软件和硬件之间的抽象接口，包含了需要编写正确运行的机器语言程序所需要的全部信息，包括[[计算机组成与设计#^785021|指令]]、寄存器、存储访问和VO等。
  
- 应用二进制接口：用户部分的指令加上应用程序员调用的[[操作系统]]接口，定义了二进制层次可移植的计算机的标准。
  
- 实现：遵循[[体系结构]]的硬件
  
    > **重点**：无论硬件还是软件都可以使用抽象分成多个层次，每个较低的层次把细节对上层隐菠起来。抽象层次中的一个关键接口是指令集[[体系结构]]-硬件和底层软件之间的接口。这一抽象接口使得同一软件可以由成本不同、性能也不同的实现方法来完成。
    

### 1.4.4 数据安全

- 易失性存储器：类似[[计算机组成与设计#^07ddc2|DRAM]]的存储器，仅在加电时保存数据。
- 非易失性存储器：在摔电时仍可保持数据的存储器，用于存储运行间的程序，例如DVD
- 主存储器：也叫主要存储器。这个存储器用来保持运行中的程序，在现代计算机中一般由[[计算机组成与设计#^07ddc2|DRAM]]组成。
- 二级存储器：非易失性存储器，用来保存两次运行之间的程序和数据。在个人移动设备中一般由[[计算机组成与设计#^c7a26d|闪存]]组成，在服务器中由磁盘组成。
- 磁盘：也叫硬盘（hard disk），是使用磁介质材料构成的以旋转盘片为基础的非男失性二级存储设备。因为是旋转的机械设备，所以碰盘的方位时间大约是5-20毫秒，2012年每g字节的价格大约为0.05-0.1美元。
- 闪存：一种非易失性半导体内存，单位价格和速度均低于DRAM，但单位价格比磁盘高，速度比磁盘快。其访问时间大约为5-50毫秒，2012年每g字节的价格大约为0.75-1美元。 ^c7a26d

### 1.4.5 与其他计算机通信

- 通信：在计算机之间高速交换信息。
- 资源共享：有些I/O设备可以由网络上的计算机共享，不必每台计算机都配备。
- 远距离访问：用户可以不必在计算机的旁边，而是在很远的地方使用计算机。
- 局城网：一种在一定地理区域（例如在同一栋大楼内）使用的传输数据的网络。
- 广城网：一种可将区域扩展到几百千米范围的网络。

## 1.5 处理器和存储器制造技术

- 晶体管：一种由电信号控制的简单开关。
- 超大规模集成电路：由数十万到数百万晶体管组成的电路。

用特殊的方法向硅中添加某些材料，可以把其细微区域转变为以下三种类型之一：

1.  良好的导电体（类似于细微的铜线或铝线）
2.  良好的绝缘体（类似于塑料或玻璃膜）
3.  可控的导电体或绝缘体（类似开关）

- 硅：一种自然元素，它是一种半导体。
- 半导体：一种导电性能不好的物质。
- 硅锭：一块由硅晶体组成的棒。直径大约在8-12英寸，长度约12-24美寸。
- 晶圆：厚度不超过0.1英寸的硅镜片，用来制造芯片。
- 瑕疵：晶圆上一个微小的缺陷，或者在图样化的过程中因为包含这个缺陷而导致芯片失效。
- 芯片：从晶圆中切割出来的一个单独的矩形区域，更加正式的英文名称是 chip ^dcfcd2
- 成品率：合格芯片数占总芯片数的百分比。

集成电路的成本可以用下面3个简单公式来表示：

1.  $每芯片的价格=\frac{每晶圆的价格}{每晶圆的芯片数×成品率}$
2.  $每晶圆的芯片\approx \frac{数晶圆面积}{芯片面积}$
3.  $成品率=\frac{1}{(1+(单位面积的瑕疵数×芯片面积/2))^2}$

## 1.6 性能

### 1.6.1 性能的定义

- 响应时间：也叫执行时间（execution time），是计算机完成某任务所需的总时间，包括硬盘访问、内存访问、VO活动、操作系统开销和CPU执行时间等。
- 吞吐率：也叫带宽（bandwidth），性能的另一种度量参数，表示单位时间内完成的任务数量。

### 1.6.2 性能的度量

- CPU执行时间：简称CPU时间，执行某一任务在CPU上所花费的时间。
- 用户CPU时间：在程序本身所花费的CPU时间。
- 系统CPU时间：为执行程序而花费在操作系统上的时间。
- 时钟周期：也叫 tick，clock tick，clock period，clock 或 cycle，为计算机一个时钟周期的时间，通常是处理器时钟，一般为常数。 ^0644ce
- 时钟长度；每个时钟周期持续的时间长度。

### 1.6.3 CPU性能及其因素

- 一个程序的CPU执行时间 = 一个程序的CPU时钟周期数 × 时钟周期时间

- 一个程序的CPU执行时间 = 一个程序的CPU时钟周期数 / 时钟频率

### 1.6.4 指令的性能

- CPU时钟周期数 = 程序的指令数 × CPI
- CPI：每条指令的[[计算机组成与设计#^0644ce|时钟周期]]数，表示执行某个程序或者程序片段时每条指令所需的时钟周期平均数。

### 1.6.5 经典的CPU性能公式

- CPU时间=指令数 × CPI × 时钟周期时间
- CPU时间=指令数 × CP / 时钟频率
- 指令数：执行某程序所需的总指令数
- 指令组合：在一个或多个程序中，指令的动态使用频度的评价指标。

## 1.7 功耗墙
- $能耗\propto 负载电容×电压^2$
- $功耗\propto 1/2×负载电容×电压^2×开关频率$

> 此前为了加强计算机的性能我们提高了时钟频率，这会日高开关频率，从而增加功耗，为了使得功耗不至于增加过多，我们降低了电压，但是怎么做会使晶体管泄露电流过大，会增加功耗。

## 1.9 实例：Intel Core i7基准

### 1.9.1 SPEC CPU基准测试程序
- 工作负载：运行在计算机上的一组程序，可以直接使用用户的一组实际应用程序，也可以从实际程序中构建。一个典型的工作负载必须指明程序和相应的频率。
- 基准测试程序：用于比较计算机性能的程序。
### 1.9.2 SPEC功耗基准测试程序

## 1.10 谬误与陷阱

***Amdabl*** 定律：阐述了“对于特定改进的性能提升可能由所使用的改进特征的数量所限制”的规则。它是“收益递减定律”的量化版本。改进后的执行时间 = 受改进影响的执行时间 / 改进量 + 不受影响的执行时间

- 谬误：
    1.  利用率低的计算机功耗低。
    2.  面向性能的设计和面向能量效率的设计具有不相关的目标。
- 陷阱：
    1.  用性能公式的一个子集去度量性能。

# 第2章 指令：计算机的语言

## 2.1 引言

- 硬件设计原则:
	1. 简单源于规整
	2. 越小越快
- 指令集：一个给定的计算机体系结构所包含的指令集合。
- 存储程序概念：多种类型的指令和数据均以数字形式存储于存储器中的概念，存储程序型计算机即源于此。

## 2.2 计算机硬件的操作


## 2.3  计算机硬件的操作数
- 字：计算机中的基本访问单位，通常是32位为一组，在MIPS体系结构中与寄存器大小相同。
### 2.3.1  存储器操作数

- 数据传送指令：在存储器和寄存器之间移动数据的命令。
- 地址：用于在存储器空间中指明某特定数据元素位置的值。
- 

### 2.3.2  常数或立即数操作数
## 2.4  有符号数和无符号数
- 反码：使用10...000表示最小负数，01...111表示最大正数，正数和负数的数量相同，但保留两个零，一个正零（00...000），一个负零（11...111）。这种方法也用来表示按位求反，即0置为1，1置为0
- 偏移表示法：最小的负数用00...000表示，最大的正数用11...11，表示，0一般用10...000表示，即通过将数加一个偏移使其具有非负的表示形式。

## 2.5  计算机中指令的表示
- 指令格式：二进制数字段组成的指令表示形式。
- 机器语言：在计算机系统中用于交流的二进制表示形式。
- 操作码：指令中用来表示操作和格式的字段。
## 2.6  逻辑操作
- 按位与：按位进行与操作，仅当两个操作位均为1时结果才为1
- 按位或：按位进行或操作，当两个操作位中任意一位为1时结果就为1
- 按位取反：按位进行非操作，仅有一个操作数，将1变成0，0变成1
- 或非：按位先或后非操作，仅当两个操作位均为0时结果才为1

> 💡可以通过左移右移操作将字的某一部分·分离出来
## 2.7  决策指令
- 条件分支：该指令先比较两个值，然后根据比较的结果决定是否从程序中的一个新地址开始执行指令序列。
### 2.7.1  循环
- 基本块：没有分支（可能出现在末尾者除外）并且没有分支目标/分支标签（可能出现在开始者除外）的指令序列。
### 2.7.2  case/switch语句
- 转移地址表：又称作转移表（jump table），指包含不同指令序列地址的表。
## 2.8  计算机硬件对过程的支持
- 过程（函数）：根据提供的参数执行一定任务的存储的子程序。
- 跳转和链接指令：跳转到某个地址的同时将下一条指令的地址保存到寄存器`$ra`中的指令。
- 返回地址：指向调用点的链接，使过程可以返回到合适的地址，在MIPS中它存储在寄存器`$ra`中。
- 调用者：调用一个过程并为过程提供必要参数值的程序。
- 被调用者：根据调用者提供的参数执行一系列存储的指令，然后将控制权返回调用者的过程。
- 程序计数器（PC）：包含在程序中正在被执行指令地址的寄存器。
### 2.8.1  使用更多的寄存器
- 栈：被组织成后进先出队列形式并用于寄存器换出的数据结构。
- 栈指针：指示栈中最近分配的地址的值，它指示寄存器被换出的位置，或寄存器旧值的存放位置。在MIPS中，栈指针是寄存器 `$sp`。
- 压栈：向栈中增加元素。
- 出栈：从栈中移除元素。
### 2.8.2  嵌套过程
- 全局指针：指向静态数据区的保留寄存器。
### 2.8.3  在栈中为新数据分配空间
- 过程帧：也称作活动记录，栈中包含过程所保存的寄存器以及局部变量的片段。
- 顿指针：指向给定过程中保存的寄存器和局部变量的值。
### 2.8.4  在堆中为新数据分配空间
- 代码段：UNIX目标文件中的段，包含源文件中例程对应的机器语言代码。
## 2.9  人机交互
## 2.10  MIPS中32位立即数和寻址
### 2.10.1  32位立即数
### 2.10.2  分支和跳转中的寻址
- PC相对寻址：一种寻址方式，它将PC和指令中的常数相加作为寻址结果。
### 2.10.3  MIPS寻址模式总结
- 寻址模式：根据对操作数和/或地址的使用不同加以区分的多种寻址方式中的一种。
	1. 立即数寻址，操作数是位于指令自身中的常数。
	2. 寄存器寻址，操作数是寄存器。
	3. 基址寻址或偏移寻址，操作数在内存中，其地址是指令中基址寄存器和常数的和。
	4. PC相对寻址，地址是PC和指令中常数的和。
	5. 伪直接寻址，跳转地址由指令中26位字段和PC高位相连而成。


### 2.10.4  机器语言解码
## 2.11  并行与指令：同步
^5acef3
- 数据竞争：假如来自不同线程的两个访存请求访问同一个地址，它们连续出现，并且至少其中一个是写操作，那么这两个存储访问形成数据竞争。
## 2.12  翻译并执行程序
### 2.12.1  编译器
- 汇编语言：一种符号语言，能被翻译成二进制的机器语言。
### 2.12.2  汇编器

### 2.12.3  链接器
### 2.12.4  加载器
### 2.12.5  动态链接库
### 2.12.6  启动一个Java程序
## 2.13  以一个C排序程序作为完整的例子
### 2.13.1  swap过程
### 2.13.2  sort过程
## 2.14  数组与指针
### 2.14.1  用数组实现clear
### 2.14.2  用指针实现clear
### 2.14.3  比较两个版本的clear
## 2.1  5  高级内容：编译C语言和解释Java语言
## 2.16  实例：ARMv7 （32位）指令集
### 2.16.1  寻址模式
### 2.16.2  比较和条件分支
### 2.16.3  ARM的特色
## 2.17实例：x86指令集
### 2.17.1  Intel x86的改进
### 2.17.2  x86寄存器和数据寻址模式
### 2.17.3  x86整数操作
### 2.17.4  x86指令编码
### 2.17.5  x86总结
## 2.18  实例：ARMv8 （64位）指令集
## 2.19  谬误与陷阱
## 2.20  本章小结
## 2.21  历史观点和拓展阅读
## 2.22  练习题
# 第3章  计算机的算术运算
## 3.1  引言
## 3.2  加法和减法
## 3.3  乘法
### 3.3.1  顺序的乘法算法和硬件
### 3.3.2  有符号乘法
### 3.3.3  更快速的乘法
### 3.3.4  MIPS中的乘法
### 3.3.5  小结
## 3.4  除法
### 3.4.1  除法算法及其硬件结构
### 3.4.2  有符号除法
### 3.4.3  更快速的除法
### 3.4.4  MIPS中的除法
### 3.4.5  小结
## 3.5  浮点运算
### 3.5.1  浮点表示
### 3.5.2  浮点加法
### 3.5.3  浮点乘法
### 3.5.4  MIPS中的浮点指令
### 3.5.5  算术精确性
### 3.5.6  小结
## 3.6  并行性和计算机算术：子字并行
## 3.7  实例：x86中流处理SIMD扩展和高级向量扩展
## 3.8  加速：子字并行和矩阵乘法
## 3.9  谬误与陷阱
## 3.10  本章小结
## 3.11  历史观点和拓展阅读
## 3.12  练习题
# 第4章  处理器
## 4.1  引言
## 4.2  逻辑设计的一般方法
## 4.3  建立数据通路
## 4.4  一个简单的实现机制
### 4.4.1  ALU控制
### 4.4.2  主控制单元的设计
### 4.4.3  为什么不使用单周期实现方式
## 4.5  流水线概述

^9ceefe

### 4.5.1  面向流水线的指令集设计
### 4.5.2  流水线冒险
### 4.5.3  对流水线概述的小结
## 4.6  流水线数据通路及其控制
### 4.6.1  图形化表示的流水线
### 4.6.2  流水线控制
## 4.7  数据冒险：旁路与阻塞
## 4.8  控制冒险
### 4.8.1  假定分支不发生
### 4.8.2  缩短分支的延迟
### 4.8.3  动态分支预测
### 4.8.4  流水线小结
## 4.9  异常
### 4.9.1  MIPS体系结构中的异常处理
### 4.9.2  在流水线实现中的异常
## 4.10  指令级并行
### 4.10.1  推测的概念
### 4.10.2  静态多发射处理器
### 4.10.3  动态多发射处理器
### 4.10.4  能耗效率与高级流水线
## 4.11  实例：ARM Cortex-A8和Intel Core i7流水线
### 4.11.1  ARM Cortex- A
### 4.11.2  Intel Core i7 
### 4.11.3  Intel Core i7 920的性能
## 4.12运行更快：指令级并行和矩阵乘法
## 4.13  高级主题：通过硬件设计语言描述和建模流水线来介绍数字设计以及更多流水线示例
## 4.14  谬误与陷阱
## 4.15  本章小结
## 4.16  历史观点和拓展阅读
## 4.17  练习题
# 第5章  大容量和高速度：开发存储器层次结构
## 5.1  引言
## 5.2  存储器技术
### 5.2.1  SRAM技术
### 5.2.2  DRAM技术
### 5.2.3  闪存
### 5.2.4  磁盘存储器
## 5.3  cache的基本原理
### 5.3.1  cache访问
### 5.3.2  cache缺失处理
### 5.3.3  写操作处理
### 5.3.4  一个cache的例子：内置FastMATH处理器
### 5.3.5  小结
## 5.4  cache性能的评估和改进
### 5.4.1  通过更灵活地放置块来减少cache缺失
### 5.4.2  在cache中查找一个块
### 5.4.3  替换块的选择
### 5.4.4  使用多级cache结构减少缺失代价
### 5.4.5  通过分块进行软件优化
### 5.4.6  小结
## 5.5  可信存储器层次
### 5.5.1  失效的定义
### 5.5.2  纠正一位错、检测两位错的汉明编码（SEC/DED）
## 5.6  虚拟机
### 5.6.1  虚拟机监视器的必备条件
### 5.6.2  指令集系统结构（缺乏）对虚拟机的支持
### 5.6.3  保护和指令集系统结构
## 5.7  虚拟存储器
### 5.7.1  页的存放和查找
### 5.7.2  缺页故障
### 5.7.3  关于写
### 5.7.4  加快地址转换：TLB
### 5.7.5  集成虚拟存储器、TLB和cache
### 5.7.6  虚拟存储器中的保护
### 5.7.7  处理TLB缺失和缺页
### 5.7.8  小结
## 5.8  存储器层次结构的一般框架
### 5.8.1  问题1：一个块可以被放在何处
### 5.8.2  问题2：如何找到一个块
### 5.8.3  问题3：当cache缺失时替换哪一块
### 5.8.4  问题4：写操作如何处理
### 5.8.5  3C：一种理解存储器层次结构行为的直观模型
## 5.9  使用有限状态机来控制简单的cache
### 5.9.1  一个简单的cache
### 5.9.2  有限状态机
### 5.9.3  一个简单的cache控制器的有限状态机
## 5.10  并行与存储器层次结构：cache一致性
### 5.10.1  实现一致性的基本方案
### 5.10.2  监听协议
## 5.11  并行与存储器层次结构：冗余廉价磁盘阵列
## 5.12  高级内容：实现cache控制器
## 5.13  实例：ARM Cortex-A8和IntelCore i7的存储器层次结构
## 5.14  运行更快：cache分块和矩阵乘法
## 5.15  谬误和陷阱
## 5.16  本章小结
## 5.17  历史观点和拓展阅读
## 5.18  练习题
# 第6章  从客户端到云的并行处理器
## 6.1  引言
## 6.2  创建并行处理程序的难点
## 6.3  SISD、MIMD、SIMD、SPMD和向量机
### 6.3.1  在x86中的SIMD：多媒体扩展
### 6.3.2  向量机
### 6.3.3  向量与标量的对比
### 6.3.4  向量与多媒体扩展的对比
## 6.4  硬件多线程
## 6.5  多核和其他共享内存多处理器
## 6.6  图形处理单元简介
### 6.6.1  NVIDIA GPU体系结构简介
### 6.6.2  NVIDIA GPU存储结构
### 6.6.3  GPU展望
## 6.7  集群、仓储级计算机和其他消息传递多处理器
## 6.8  多处理器网络拓扑简介
## 6.9  与外界通信：集群网络
## 6.10  多处理器测试集程序和性能模型
### 6.10.1  性能模型
### 6.10.2  Roofline模型
### 6.10.3  两代Opteron的比较
## 6.11  实例：评测Intel Core i7 960和NVIDIA Tesla GPU的Roofline模型
## 6.12  运行更快：多处理器和矩阵乘法
## 6.13  谬误与陷阱
## 6.14  本章小结
## 6.15  历史观点和拓展阅读
## 6.16  练习题